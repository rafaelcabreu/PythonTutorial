{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scipy\n",
    "\n",
    "SciPy é uma coleção de algoritmos matemáticos e funções convenientes construídas em cima do **NumPy**. Adiciona significativo poder para a sessão Python proporcionando ao usuário comandos de alto nível e classes para manipular e visualizar dados.\n",
    "\n",
    "* Pacote de Cluster (scipy.cluster)\n",
    "* Constantes (scipy.constants)\n",
    "* Transformada de Fourier discreta (scipy.fftpack)\n",
    "* Integração numérica e solução de ODEs (scipy.integrate)\n",
    "* **Interpolação (scipy.interpolate)**\n",
    "* Input e output (scipy.io)\n",
    "* Algebra linear (scipy.linalg)\n",
    "* Rotinas diversas (scipy.misc)\n",
    "* Processamento de imagens n-dimensionais (scipy.ndimage)\n",
    "* <p><span style=\"color:red\">Orthogonal distance regression (scipy.odr)</p>\n",
    "* Optimização e solução de sistemas (scipy.optimize)\n",
    "* Processamento de sinais (scipy.signal)\n",
    "* <p><span style=\"color:red\">Sparse matrices (scipy.sparse)</p>\n",
    "* <p><span style=\"color:red\">Sparse linear algebra (scipy.sparse.linalg)</p>\n",
    "* <p><span style=\"color:red\">Compressed Sparse Graph Routines (scipy.sparse.csgraph)</p>\n",
    "* <p><span style=\"color:red\">Spatial algorithms and data structures (scipy.spatial)</p>\n",
    "* Funções especiais (scipy.special)\n",
    "* **Funções estatísticas (scipy.stats)**\n",
    "* Funções estatísticas para arrays mascarados (scipy.stats.mstats)\n",
    "* <p><span style=\"color:red\">Low-level callback functions</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe `interp1d` permite que a partir de um conjunto de pontos nós possamos criar uma função de interpolação dentro desse domínio. Por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 20, 21)\n",
    "y = np.cos((x * np.pi) ** 2 / 2)\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função de interpolação default linear\n",
    "f = interp1d(x, y)\n",
    "f2 = interp1d(x, y, kind='cubic')\n",
    "\n",
    "xnew = np.linspace(0, 20, 100)\n",
    "plt.plot(x, y, 'o') \n",
    "plt.plot(xnew, f(xnew), '-') \n",
    "plt.plot(xnew, f2(xnew), '--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Em que situação isso pode ser usado?</b> Imagine que você tem uma série de dados de temperatura que possui várias falhas. Isso pode ser usado para preencher essas falhas de forma simples\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos tentar interpolar um campo de duas dimensões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-5.01, 5.01, 0.25)\n",
    "y = np.arange(-5.01, 5.01, 0.25)\n",
    "xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "z = np.sin(xx**2+yy**2)\n",
    "\n",
    "# aumentamos a grade para pontos a cada 0.01\n",
    "xnew = np.arange(-5.01, 5.01, 1e-2)\n",
    "ynew = np.arange(-5.01, 5.01, 1e-2)\n",
    "xxnew, yynew = np.meshgrid(xnew, ynew)\n",
    "\n",
    "f = interp2d(x, y, z, kind='cubic')\n",
    "\n",
    "znew = f(xnew, ynew)\n",
    "\n",
    "fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(16,6))\n",
    "\n",
    "ax1.pcolormesh(xx, yy, z)\n",
    "ax2.pcolormesh(xxnew, yynew, znew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Em que situação isso pode ser usado?</b> Imagine que você tem dados observacionais em pontos de grade divididos em uma malha de 0.25° x 0.25° de lat/lon e quer comparar com o GFS de 1° x 1°. Dessa forma você pode reinterpolar seus dados observados para a grade do GFS de 1° x 1° para comparar de forma mais homogênea.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E se tivessemos dados não estruturados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npts = 200\n",
    "\n",
    "# pontos (coordeanadas)\n",
    "x = np.random.uniform(-2,2,npts)\n",
    "y = np.random.uniform(-2,2,npts)\n",
    "# valor no dado ponto (ex: temperatura)\n",
    "z = x*np.exp(-x**2-y**2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "cf = ax.scatter(x, y, c=z)\n",
    "fig.colorbar(cf, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minha grade\n",
    "xi = np.linspace(-2.1,2.1,100)\n",
    "yi = np.linspace(-2.1,2.1,100)\n",
    "xx, yy = np.meshgrid(xi, yi)\n",
    "\n",
    "grid_z0 = griddata((x, y), z, (xx, yy), method='nearest')\n",
    "grid_z1 = griddata((x, y), z, (xx, yy), method='linear', fill_value=0)\n",
    "grid_z2 = griddata((x, y), z, (xx, yy), method='cubic', fill_value=0)\n",
    "\n",
    "fig, axarr = plt.subplots(2, 2, figsize=(16,8))\n",
    "\n",
    "axarr[0, 0].pcolormesh(xx, yy, xx*np.exp(-xx**2-yy**2))\n",
    "axarr[0, 0].scatter(x, y, color='k')\n",
    "axarr[0, 1].pcolormesh(xx, yy, grid_z0)\n",
    "axarr[1, 0].pcolormesh(xx, yy, grid_z1)\n",
    "axarr[1, 0].contour(xx, yy, grid_z1, colors='k')\n",
    "axarr[1, 1].contourf(xx, yy, grid_z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Em que situação isso pode ser usado?</b> Imagine que você tem dados de temperatura de várias estações e quer\n",
    "fazer uma mapa com esses dados em pontos de grade para talvez comparar com um modelo, ou simplesmente para \n",
    "facilitar a visualização.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Estatística\n",
    "\n",
    "O que temos de estatística no scipy? https://docs.scipy.org/doc/scipy/reference/stats.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(2, 2, figsize=(16,10))\n",
    "\n",
    "# distribuição normal\n",
    "x = np.linspace(stats.norm.ppf(0.01), stats.norm.ppf(0.99), 100)\n",
    "axarr[0, 0].plot(x, stats.norm.pdf(x, loc=0, scale=1), c='r', lw=5, alpha=0.6, label='norm pdf')\n",
    "axarr[0, 0].set_title(u'Distribuição Normal')\n",
    "\n",
    "# distribuição gamma\n",
    "x = np.linspace(stats.gamma.ppf(0.01, 1.99), stats.gamma.ppf(0.99, 1.99), 100)\n",
    "axarr[0, 1].plot(x, stats.gamma.pdf(x, 1.99), c='r', lw=5, alpha=0.6, label='norm pdf')\n",
    "axarr[0, 1].set_title(u'Distribuição Gamma')\n",
    "\n",
    "# distribuição exponencial\n",
    "x = np.linspace(stats.expon.ppf(0.01), stats.expon.ppf(0.99), 100)\n",
    "axarr[1, 0].plot(x, stats.expon.pdf(x), c='r', lw=5, alpha=0.6, label='norm pdf')\n",
    "axarr[1, 0].set_title(u'Distribuição Exponencial')\n",
    "\n",
    "# distribuição uniforme\n",
    "x = np.linspace(stats.uniform.ppf(0.01), stats.uniform.ppf(0.99), 100)\n",
    "axarr[1, 1].plot(x, stats.uniform.pdf(x), c='r', lw=5, alpha=0.6, label='norm pdf')\n",
    "axarr[1, 1].set_title(u'Distribuição Uniforme')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 6\n",
    "\n",
    "Dada duas séries de dados $a \\sim N(2,2)$ e $b \\sim N(0,1)$ com 100 elementos cada, faça uma figura que contenha dois subplots contendo: 1. A série de dados, 2. O histograma normalizado com o ajuste das PDF (Não se esqueça de nomear os eixos e de da adicionar uma legenda)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas funções e testes úteis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.normal(loc=2, scale=2, size=100)\n",
    "b = np.random.normal(loc=0, scale=1, size=100)\n",
    "\n",
    "r, pvalue = stats.pearsonr(a, b)\n",
    "\n",
    "print 'Coeficiente de correlação de pearson é:', r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic, pvalue = stats.ttest_ind(a, b)\n",
    "\n",
    "if pvalue > 0.05: # nível de significância\n",
    "    print 'Não podemos rejeitar H_0, a hipótese que as distribuições tem médias idênticas pois pvalue =', pvalue\n",
    "else:\n",
    "    print 'Podemos rejeitar H_0, a hipótese que as distribuições tem médias idênticas pois pvalue =', pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Em que situação isso pode ser usado?</b> Em clima muitas vezes isso pode ser utilizado. Imagine que você quer estudar eventos de ZCAS, você separa todas as ocorrências desse fenômeno e quer comparar os padrões de circulação. Com todos os eventos de ZCAS comparando com os eventos de não ZCAS você consegue com isso identificar o quão significativa são as diferenças que você encontrou nos padrões atmosféricos.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic, pvalue = stats.kstest(b, 'norm')\n",
    "\n",
    "if pvalue > 0.05: # nível de significância\n",
    "    print 'Não podemos rejeitar H_0, a hipótese de que y vem da distribuição N(0,1), pois pvalue =', pvalue\n",
    "else:\n",
    "    print 'Podemos rejeitar H_0, a hipótese de que y vem da distribuição N(0,1) pois pvalue =', pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Em que situação isso pode ser usado?</b> Testes de normalidade ou de outras distribuições geralmente são usados quando você precisa que determinada condição de distribuição seja satisfeita para que um modelo ou um teste seja feito. O caso do teste T indicado anteriormente pode ser usado como exemplo: para que ele possa ser utilizado é necessário que as distribuições sejam gaussianas.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic, pvalue = stats.ks_2samp(a, b)\n",
    "\n",
    "if pvalue > 0.05: # nível de significância\n",
    "    print 'Não podemos rejeitar H_0, a hipótese de que y1 vem da mesma distribuição que y2, pois pvalue =', pvalue\n",
    "else:\n",
    "    print 'Podemos rejeitar H_0, a hipótese de que y1 vem da mesma distribuição que y2 pois pvalue =', pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Em que situação isso pode ser usado?</b> Imagine que você tem dados de temperatura de um modelo e das observações. Um jeito de avaliar o quão confiável o modelo é pode ser usando um teste desse tipo em que as distribuições de duas amostras são comparadas entre si.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Pandas é um pacote Python que proporciona estruturas de dados rápidas, flexivas e expressivas, desenhadas para fazer trabalhar com dados \"relacionais\" ou \"nomeados\" fácil e inuitivo. Pandas é usado para diferentes tipos de dados:\n",
    "\n",
    "- Dados tabelados como SQL e Excel\n",
    "- Séries temporais ordenadas ou não ordenadas\n",
    "- Matrizes com nomes nas colunas e linhas\n",
    "- Qualquer tipo de dado que seja nomeado\n",
    "\n",
    "(http://pandas.pydata.org/pandas-docs/stable/getting_started/overview.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Series` é um array unidimensional capaz de receber dado de qualquer tipo (inteiro, strings, float, objetos, etc.). Os nomes nos eixo são geralmente chamados de índice ou index. O método para se criar uma série é:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 3, 5, np.nan, 6, 8])\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame` é uma estrutura de dados bidimensional nomeada (labeled) com colunas que podem ser de tipos diferentes. Você pode pensar nele como uma planolha de Excel ou uma tabela SQL, ou um dicionário com várias `Series`. É o objeto mais usado no pandas. Assim como `Series`, o `DataFrame` também consegue receber vários tipos diferentes de dados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('20130101', periods=6, freq='M')\n",
    "\n",
    "print 'dates = ', dates\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=['A', 'B', 'C', 'D'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'A': 1.,\n",
    "                    'B': pd.Timestamp('20130102'),\n",
    "                    'C': pd.Series(1, index=list(range(4)), dtype='float32'),\n",
    "                    'D': np.array([3] * 4, dtype='int32'),\n",
    "                    'E': pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n",
    "                    'F': 'foo'})\n",
    "\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para abrir arquivos geralmente usamos o comando `pd.read_csv()`. Esse comando pode ser usado para qualquer tipo de arquivo texto, não necessariamente apenas os que terminam com `.csv`. Vamos usar como exemplo a série histórica da estação Mirante de Santana do INMET que está na pasta **data**. O método `read_csv` tem os seguintes argumentos:\n",
    "\n",
    "`pandas.read_csv(filepath_or_buffer, sep=', ', delimiter=None, header='infer', names=None, index_col=None, usecols=None, squeeze=False, prefix=None, mangle_dupe_cols=True, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, skip_blank_lines=True, parse_dates=False, infer_datetime_format=False, keep_date_col=False, date_parser=None, dayfirst=False, iterator=False, chunksize=None, compression='infer', thousands=None, decimal=b'.', lineterminator=None, quotechar='\"', quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, dialect=None, tupleize_cols=None, error_bad_lines=True, warn_bad_lines=True, delim_whitespace=False, low_memory=True, memory_map=False, float_precision=None)`\n",
    "\n",
    "(https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/inmconv_83781.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Precipitacao'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('Precipitacao', ascending=False).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode selecionar os dados pelas labels do índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['19800101':'19800105']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['2000-01-01', ['TempMaxima', 'TempMinima']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou pelo índice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[9:12, [4, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou mesmo por booleano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Precipitacao'] > 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Precipitacao'] > 1].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Em que situação isso pode ser usado?</b> Qualquer tipo de série temporal. Você pode estar interessado apenas em casos de chuva ou temperatura acima de um limiar particular. Isso pode ser um valor numérico ou mesmo um percentil, por exemplo.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preenchendo Falhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmax = df['TempMaxima'].to_frame() # vamos usar a temperatura máxima apenas por enquanto\n",
    "\n",
    "df_tmax.dropna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmax.fillna(value=999).head() # argumento inplace=True é o mesmo que df_tmax = df_tmax.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmax.fillna(method='ffill').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos interpolar também: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.interpolate.html#pandas.DataFrame.interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmax.interpolate(method='linear').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Atenção:</b> Aqui existe uma diferença importante entre usar o pandas e o numpy. O pandas não considera as falhas, ou seja, os NaN nos cálculos (médias, cálculo de percentis, etc.). Dessa forma, suponha que você tenha 1000 dados na sua série e 100 faltantes, e quer calcular uma média. Esse valor será calculado com relação à esses 900 dados da série e não aos 1000. Já abrindo o arquivo diretamente no numpy ele não entende o que são os dados faltantes, logo qualquer operação feita com dados faltantes retornará NaN.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling dos dados\n",
    "\n",
    "Lidando com séries temporais geralmente estamos interessados em médias, máximos, mínimos, percentis diários, mensais, climatológicos. O pandas tem funções bem práticas para isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmax.dropna(inplace=True) # removendo os missing data\n",
    "\n",
    "# versões mais antigas do pandas devem ser escritas como df_tmax.resample('M', how='mean')\n",
    "df_tmax_month = df_tmax.resample('M').mean() # pode ser substituido por min, max, sum, por exemplo.\n",
    "\n",
    "df_tmax_month.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmax.resample('AS').max().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos calcular uma climatologia dos dados também com a função `groupby` (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clim = df_tmax['1961':'1990'] # geralmente usamos 1961 a 1990 como base para a climatologia\n",
    "\n",
    "df_clim.groupby(df_clim.index.month).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções úteis para plots com o pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,5))\n",
    "\n",
    "df_tmax.plot(ax=ax, alpha=0.5)\n",
    "df_tmax.resample('M').mean().plot(ax=ax, linewidth=2)\n",
    "df_tmax.resample('AS').mean().plot(ax=ax, linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a precipitação por exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prec_month = df.loc['1961':'1990', 'Precipitacao'].resample('M').sum()\n",
    "df_clim = df_prec_month.groupby(df_prec_month.index.month).mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,5))\n",
    "\n",
    "df_clim.plot(kind='bar', color='C0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando funções a um DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[4, 9],] * 3, columns=['A', 'B'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(np.sqrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode aplicar algumas funções ao longo de um eixo (`axis`) específico ainda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(np.sum, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(np.sum, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode ainda usar funções definidas por você, ou funções anônimas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda x: x ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_row(row):\n",
    "    return row['A'] + row['B']\n",
    "\n",
    "df.apply(sum_row, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 7\n",
    "\n",
    "Dada a série de dados em `data/inmconv_83781.csv` calculate a anomalia de precipitação mensal com base no período de 1961 a 1990 e identifique quais são os três anos com Dezembro mais secos da série histórica (menor anomalia). Faça uma figura com a anomalia não se esquecendo de nomear os eixos da figura e dar nome (label) à série."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
